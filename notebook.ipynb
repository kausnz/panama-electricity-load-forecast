{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_file = 'data/continuous_dataset.csv'\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "data_file = 'data/weekly_pre_dispatch_forecast.csv'\n",
    "df_forecast_pre_dispatch = pd.read_csv(data_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This dataset contains the feature variables and dependent variable datetime.\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load forecast in the pre dispatch reports is the prediction made by the grid operator.\n",
    "# This is not a feature for our model but could be compared with our predictions as an exploratory activity.\n",
    "df_forecast_pre_dispatch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Checking if there are missing values. None found.\n",
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Making columns lower case for better readability.\n",
    "df.columns = df.columns.str.lower()\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check the data types of the variables\n",
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Checking if variable `school` has non-boolean values\n",
    "df.school.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Checking if variable `holiday` has non-boolean values\n",
    "df.holiday.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking if 0's in `holiday_id` matches the number of holidays based on `holiday`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert df.holiday_id.value_counts()[0] == df.holiday.value_counts()[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# datetime is a string. Splitting it to multiple columns will make plotting easier.\n",
    "# Therefore, creating a new variable called `dt` of type pd.datetime by converting the values from `df.datetime`.\n",
    "df['dt'] = pd.to_datetime(df.datetime, format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Checking if there are datetime conversion errors.\n",
    "assert df.dt.isnull().sum() == 0\n",
    "\n",
    "# delete datetime from the dataframe as dt supersedes it now.\n",
    "del df['datetime']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['dt_year'] = df['dt'].dt.year\n",
    "df['dt_month'] = df['dt'].dt.month\n",
    "df['dt_day'] = df['dt'].dt.day\n",
    "df['dt_hour'] = df['dt'].dt.hour\n",
    "\n",
    "# No need to separate minute and second values as they are always 0. Verified and confirmed.\n",
    "# df['dt_minute'] = df.datetime.dt.minute\n",
    "# df['dt_second'] = df.datetime.dt.second\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visually check all dt variables that they've been split correctly from a semantic viewpoint.\n",
    "# Programmatic check was done above by checking for conversion errors.\n",
    "df[df.columns[df.columns.str.match('^dt.*')]][::100]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.groupby(by=['dt_year', 'dt_month']).size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df[['t2m_toc', 't2m_san', 't2m_dav', 'dt_year', 'dt_month']].groupby(by=['dt_year', 'dt_month'], group_keys=True).max().plot().bar()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# distribution of the target variable\n",
    "# %matplotlib inline\n",
    "# plt.figure(figsize=(10,10))\n",
    "# sns.histplot(df.nat_demand)\n",
    "# sns.histplot(y_pred, color='red', bins=50, alpha=0.5)\n",
    "\n",
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.nat_demand"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(df.nat_demand, color='red', bins=50, alpha=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# See the distribution of the log1p version of the target variable\n",
    "sns.histplot(np.log1p(df.nat_demand), color='red', bins=50, alpha=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Focusing on the long tail on the left. They seem to be outliers.\n",
    "plt.xlim(0, 1000)\n",
    "plt.ylim(0, 10)\n",
    "sns.histplot(df.nat_demand, color='red', bins=50, alpha=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Looks like there are 8 very low demands. This is only a 0.017% of the total records.\n",
    "# Without these outliers the national demand values are 'normally' distributed.\n",
    "# Therefore, no need to log1p() the values.\n",
    "round(df.nat_demand[df.nat_demand < 600].size / len(df.nat_demand) * 100, 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(df.nat_demand[df.nat_demand > 600], color='red', bins=50, alpha=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Splitting the dataset to 80%, 20%, 20% for training, validation, and testing, respectively.\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "print(f'train:val:test split is {(len(df_train), len(df_val), len(df_test))}')\n",
    "\n",
    "# Also create a copy of the complete dataframe with order intact to plot actual vs forecast based on the final model.\n",
    "df_full = df.copy()\n",
    "print(f'complete dataset is {len(df_full)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Resetting indices\n",
    "df_full_train.reset_index(inplace=True)\n",
    "df_train.reset_index(inplace=True)\n",
    "df_val.reset_index(inplace=True)\n",
    "df_test.reset_index(inplace=True)\n",
    "df_full.reset_index(\n",
    "    inplace=True)  # not necessary, but done so the for-loop below doesn't fail due to not having an index column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_full_train = df_full_train.nat_demand\n",
    "y_train = df_train.nat_demand\n",
    "y_val = df_val.nat_demand\n",
    "y_test = df_test.nat_demand\n",
    "y_full = df_full.nat_demand\n",
    "\n",
    "# log1p\n",
    "# y_train = np.log1p(df_train.nat_demand)\n",
    "# y_val = np.log1p(df_val.nat_demand)\n",
    "# y_test = np.log1p(df_test.nat_demand)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_full"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Removing unwanted variables\n",
    "for c in ['nat_demand', 'dt', 'index']:\n",
    "    del df_full_train[c]\n",
    "    del df_train[c]\n",
    "    del df_val[c]\n",
    "    del df_test[c]\n",
    "    del df_full[c]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Vectorize the features\n",
    "dv = DictVectorizer(sparse=False)\n",
    "train_dicts = df_train.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "test_dicts = df_test.to_dict(orient='records')\n",
    "X_test = dv.transform(test_dicts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest\n",
    "\n",
    "Training a Random Forest Regressor by tuning 3 of its parameters, viz. n_estimators, max_depth and min_samples_leaf, to derive the best (lowest) RMSE score. The resulting RMSE will be set as the baseline. Once the baseline is set, an XGBoost Regressor will be trained and evaluated to see if we can achieve a model with a better RMSE."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Benchmark 1\n",
    "Train a model and measure performance with default `n_estimators`, `max_depth` and `\n",
    "` values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,\n",
    "                           max_depth=None,\n",
    "                           min_samples_leaf=1,\n",
    "                           random_state=1,\n",
    "                           n_jobs=-1)\n",
    "model = rf.fit(X_train, y_train)\n",
    "y_val_pred = rf.predict(X_val)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Feature importance (Gini)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ft_imp = list(zip(rf.feature_importances_, dv.get_feature_names_out()))\n",
    "df_ft_imp = pd.DataFrame(ft_imp, columns=['score', 'feature']).sort_values(by='score', ascending=True)\n",
    "plt.barh(df_ft_imp.feature, df_ft_imp.score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_performance = [('rmse', np.sqrt(mean_squared_error(y_val, y_val_pred))),\n",
    "                  ('mae', mean_absolute_error(y_val, y_val_pred))]\n",
    "pd.DataFrame(rf_performance, columns=['metric', 'score'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Benchmark 2\n",
    "Training the model with tuned parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Feature importance (Gini)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tune `n_estimators` and `max_depth`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Finding the optimal max_depth and n_estimators\n",
    "scores = []\n",
    "for d in tqdm([20, 25, 30, 35, 40, 45, 50]):\n",
    "    for n in tqdm(range(10, 201, 20)):\n",
    "        rf = RandomForestRegressor(n_estimators=n,\n",
    "                                   max_depth=d,\n",
    "                                   random_state=1,\n",
    "                                   n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_val_pred = rf.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "        mae = mean_absolute_error(y_val, y_val_pred)\n",
    "        scores.append((n, d, rmse, mae))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(scores, columns=['n_estimators', 'max_depth', 'rmse', 'mae'])\n",
    "df_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 6))\n",
    "plt.xlabel('No. of estimators')\n",
    "plt.ylabel('RMSE')\n",
    "for d in tqdm([20, 25, 30, 35, 40, 45, 50]):\n",
    "    plt.plot(df_scores[df_scores.max_depth == d].n_estimators,\n",
    "             df_scores[df_scores.max_depth == d].rmse,\n",
    "             label=f'max_depth={d}')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tune `min_samples_leaf`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Based on the above graph, optimal max_depth is 30.\n",
    "max_depth = 30\n",
    "\n",
    "# Finding the optimal min_samples_leaf\n",
    "scores = []\n",
    "for s in tqdm([1, 3, 5, 10, 50]):\n",
    "    for n in tqdm(range(10, 201, 20)):\n",
    "        rf = RandomForestRegressor(n_estimators=n,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_leaf=s,\n",
    "                                   random_state=1,\n",
    "                                   n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_val_pred = rf.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "        mae = mean_absolute_error(y_val, y_val_pred)\n",
    "        scores.append((n, s, rmse, mae))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(scores, columns=['n_estimators', 'min_samples_leaf', 'rmse', 'mae'])\n",
    "df_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 8))\n",
    "plt.xlabel('No. of estimators')\n",
    "plt.ylabel('RMSE')\n",
    "for s in [1, 3, 5, 10, 50]:\n",
    "    plt.plot(df_scores[df_scores.min_samples_leaf == s].n_estimators,\n",
    "             df_scores[df_scores.min_samples_leaf == s].rmse,\n",
    "             label=f'min_samples_leaf={s}')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_estimators = 150\n",
    "max_depth = 30\n",
    "min_samples_leaf = 1\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                           max_depth=max_depth,\n",
    "                           min_samples_leaf=min_samples_leaf,\n",
    "                           random_state=1,\n",
    "                           n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_val_pred = rf.predict(X_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ft_imp = list(zip(rf.feature_importances_, dv.get_feature_names_out()))\n",
    "df_ft_imp = pd.DataFrame(ft_imp, columns=['score', 'feature']).sort_values(by='score', ascending=True)\n",
    "plt.barh(df_ft_imp.feature, df_ft_imp.score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "rf_performance = [('rmse', rmse),\n",
    "                  ('mae', mae)]\n",
    "pd.DataFrame(rf_performance, columns=['metric', 'score'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Result:**\n",
    "Benchmark 2 results is slightly better than Benchmark 1. Therefore, Benchmark 2 will be used as the benchmark for the model performance and will be used for comparison when measuring performance of the gradient boosting models in the next section."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune `eta`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = dv.get_feature_names_out()\n",
    "dm_train = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "dm_val = xgb.DMatrix(X_val, label=y_val, feature_names=features)\n",
    "dm_test = xgb.DMatrix(X_test, label=y_test, feature_names=features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_gb_model(dm_train,\n",
    "                   eta=0.3,\n",
    "                   max_depth=6,\n",
    "                   min_child_weight=1,\n",
    "                   num_boost_round=201,\n",
    "                   watchlist=[(dm_train, 'train'), (dm_val, 'val')]):\n",
    "    xgb_params = {\n",
    "        'eta': eta,\n",
    "        'max_depth': max_depth,\n",
    "        'min_child_weight': min_child_weight,\n",
    "\n",
    "        'eval_metric': 'rmse',\n",
    "        'objective': 'reg:squarederror',\n",
    "        'nthread': -1,\n",
    "\n",
    "        'seed': 1,\n",
    "        'verbosity': 1\n",
    "    }\n",
    "    evals_result = {}\n",
    "    model = xgb.train(params=xgb_params,\n",
    "                      dtrain=dm_train,\n",
    "                      num_boost_round=num_boost_round,\n",
    "                      evals=watchlist,\n",
    "                      evals_result=evals_result,\n",
    "                      verbose_eval=False)\n",
    "\n",
    "    columns = ['eta', 'iter', 'train_rmse', 'val_rmse']\n",
    "    train_rmse_scores = list(evals_result['train'].values())[0] if watchlist is not None else []\n",
    "    val_rmse_scores = list(evals_result['val'].values())[0] if watchlist is not None else []\n",
    "\n",
    "    df_scores = pd.DataFrame(\n",
    "        list(zip([eta] * len(train_rmse_scores),\n",
    "                 range(1, len(train_rmse_scores) + 1),\n",
    "                 train_rmse_scores,\n",
    "                 val_rmse_scores\n",
    "                 )), columns=columns)\n",
    "    return model, df_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = pd.DataFrame()\n",
    "for eta in tqdm([0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 1.0]):\n",
    "    key = f'eta={eta}'\n",
    "    _, df_scores = train_gb_model(dm_train,\n",
    "                                  eta=eta,\n",
    "                                  num_boost_round=201)\n",
    "    scores = pd.concat([scores, df_scores])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores.sort_values(by='val_rmse', ascending=True).reset_index().iloc[::200]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "axs[0].set_title('Learning Rate - RMSE')\n",
    "axs[0].set_xlabel('Iterations')\n",
    "axs[0].set_ylabel('RMSE (validation dataset)')\n",
    "gs = scores.groupby('eta')\n",
    "gs.get_group(1.00)\n",
    "gs.groups.values()\n",
    "for eta in gs.groups.keys():\n",
    "    df = gs.get_group(eta)\n",
    "    axs[0].plot(df.iter, df.val_rmse, label=f'eta={eta}')\n",
    "    axs[0].legend()\n",
    "\n",
    "axs[1].set_title('Learning Rate - RMSE (Zoomed)')\n",
    "axs[1].set_xlabel('Iterations')\n",
    "axs[1].set_ylabel('RMSE (validation dataset)')\n",
    "axs[1].set_xlim([175, 200])\n",
    "axs[1].set_ylim([75, 80])\n",
    "gs = scores.groupby('eta')\n",
    "gs.get_group(1.00)\n",
    "gs.groups.values()\n",
    "for eta in gs.groups.keys():\n",
    "    df = gs.get_group(eta)\n",
    "    axs[1].plot(df.iter, df.val_rmse, label=f'eta={eta}')\n",
    "    axs[1].legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Base on the above analysis, eta=0.3 gives the best performance as the learning rate.\n",
    "chosen_eta = 0.3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune `max_depth`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for max_depth in [3, 4, 6, 10, 14, 18]:\n",
    "    key = f'max_depth={max_depth}'\n",
    "    _, scores[key] = train_gb_model(dm_train,\n",
    "                                    eta=chosen_eta,\n",
    "                                    max_depth=max_depth,\n",
    "                                    num_boost_round=201)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "axs[0].set_title('Max Depth - RMSE')\n",
    "axs[0].set_xlabel('Iterations')\n",
    "axs[0].set_ylabel('RMSE (validation dataset)')\n",
    "for key, df_scores in scores.items():\n",
    "    axs[0].plot(df_scores.iter, df_scores.val_rmse, label=key)\n",
    "    axs[0].legend()\n",
    "\n",
    "axs[1].set_title('Max Depth - RMSE (Zoomed)')\n",
    "axs[1].set_xlabel('Iterations')\n",
    "axs[1].set_ylabel('RMSE (validation dataset)')\n",
    "axs[1].set_xlim([175, 200])\n",
    "axs[1].set_ylim([70, 100])\n",
    "for key, df_scores in scores.items():\n",
    "    axs[1].plot(df_scores.iter, df_scores.val_rmse, label=key)\n",
    "    axs[1].legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The above analysis shows max_depth=10 gies the best performance.\n",
    "chosen_max_depth = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune `min_child_weight`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for min_child_weight in [1, 10, 30, 40]:\n",
    "    key = f'min_child_weight={min_child_weight}'\n",
    "    _, scores[key] = train_gb_model(dm_train,\n",
    "                                    eta=chosen_eta,\n",
    "                                    max_depth=chosen_max_depth,\n",
    "                                    min_child_weight=min_child_weight,\n",
    "                                    num_boost_round=201)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "axs[0].set_title('Min Child Weight - RMSE')\n",
    "axs[0].set_xlabel('Iterations')\n",
    "axs[0].set_ylabel('RMSE (validation dataset)')\n",
    "for min_child_weight, df in scores.items():\n",
    "    df = scores[min_child_weight]\n",
    "    axs[0].plot(df.iter, df.val_rmse, label=min_child_weight)\n",
    "    axs[0].legend()\n",
    "\n",
    "axs[1].set_title('Min Child Weight - RMSE (Zoomed)')\n",
    "axs[1].set_xlabel('Iterations')\n",
    "axs[1].set_ylabel('RMSE (validation dataset)')\n",
    "axs[1].set_xlim([175, 200])\n",
    "axs[1].set_ylim([70, 73])\n",
    "for min_child_weight, df in scores.items():\n",
    "    df = scores[min_child_weight]\n",
    "    axs[1].plot(df.iter, df.val_rmse, label=min_child_weight)\n",
    "    axs[1].legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The above analysis shows min_child_weight=30 gives the best performance.\n",
    "chosen_min_child_weight = 30"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Final GB model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training the model with train set and the chosen values for the parameters\n",
    "\n",
    "(model, scores) = train_gb_model(dm_train=dm_train,\n",
    "                                 eta=chosen_eta,\n",
    "                                 max_depth=chosen_max_depth,\n",
    "                                 min_child_weight=chosen_min_child_weight,\n",
    "                                 num_boost_round=201)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ft_imp = pd.DataFrame.from_dict(model.get_score(importance_type='weight'), orient='index').sort_values(by=0,\n",
    "                                                                                                          ascending=True)\n",
    "df_ft_imp.columns = ['score']\n",
    "df_ft_imp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.barh(df_ft_imp.index, df_ft_imp.score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gb_rmse = scores.sort_values(by='val_rmse').iloc[0, 3]\n",
    "print(f'rmse of xgb model on test set = {gb_rmse}')\n",
    "\n",
    "full_dicts = df_full.to_dict(orient='records')\n",
    "X_full = dv.transform(full_dicts)\n",
    "dm_full = xgb.DMatrix(X_full, label=y_full, feature_names=features)\n",
    "\n",
    "y_full_pred = model.predict(dm_full)\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "load_period = 24 * 14\n",
    "actual = y_full[:load_period]\n",
    "predict = y_full_pred[:load_period]\n",
    "plt.plot(actual.index, list(actual), label='Actual Load')\n",
    "plt.plot(actual.index, list(predict), color='red', label='Forecast')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Load (MWh)')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training with full_train and chosen params, and measure the performance\n",
    "full_train_dicts = df_full_train.to_dict(orient='records')\n",
    "X_full_train = dv.transform(full_train_dicts)\n",
    "dm_full_train = xgb.DMatrix(X_full_train, label=y_full_train, feature_names=features)\n",
    "(model, scores) = train_gb_model(dm_train=dm_full_train,\n",
    "                                 eta=chosen_eta,\n",
    "                                 max_depth=chosen_max_depth,\n",
    "                                 min_child_weight=chosen_min_child_weight,\n",
    "                                 num_boost_round=201,\n",
    "                                 watchlist=[(dm_full_train, 'train'), (dm_test, 'val')])\n",
    "gb_rmse = scores.sort_values(by='val_rmse').iloc[0, 3]\n",
    "print(f'rmse of xgb model on full_train set = {gb_rmse}')\n",
    "\n",
    "# We get much better RMSE compared to what we got from train set. Let's plot the full timeseries with predictions from the new model.\n",
    "y_full_pred = model.predict(dm_full)\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "load_period = 24 * 14\n",
    "actual = y_full[:load_period]\n",
    "predict = y_full_pred[:load_period]\n",
    "plt.plot(actual.index, list(actual), label='Actual Load')\n",
    "plt.plot(actual.index, list(predict), color='red', label='Forecast')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Load (MWh)')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import bentoml\n",
    "\n",
    "# retraining without the feature_names in the dmatrix, as otherwise predict() will fail later in the pipeline.\n",
    "dm_full_train = xgb.DMatrix(X_full_train, label=y_full_train)\n",
    "(model, scores) = train_gb_model(dm_train=dm_full_train,\n",
    "                                 eta=chosen_eta,\n",
    "                                 max_depth=chosen_max_depth,\n",
    "                                 min_child_weight=chosen_min_child_weight,\n",
    "                                 num_boost_round=201,\n",
    "                                 watchlist=None)\n",
    "bentoml.xgboost.save_model(\"load_forecast_model\", model,\n",
    "                           custom_objects={\n",
    "                               \"dictVectorizer\": dv\n",
    "                           },\n",
    "                           signatures={\n",
    "                               \"predict\": {\n",
    "                                   \"batchable\": True,\n",
    "                                   \"batch_dim\": 0\n",
    "                               }\n",
    "                           })"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test request payload from dict(df_test.iloc[0])\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"t2m_toc\": 25.6113220214844,\n",
    "  \"qv2m_toc\": 0.01747758,\n",
    "  \"tql_toc\": 0.043762207,\n",
    "  \"w2m_toc\": 15.885400482402956,\n",
    "  \"t2m_san\": 23.8613220214844,\n",
    "  \"qv2m_san\": 0.016439982,\n",
    "  \"tql_san\": 0.03894043,\n",
    "  \"w2m_san\": 6.2321456709303815,\n",
    "  \"t2m_dav\": 22.9472595214844,\n",
    "  \"qv2m_dav\": 0.01531083,\n",
    "  \"tql_dav\": 0.062301636,\n",
    "  \"w2m_dav\": 3.6011136954933645,\n",
    "  \"holiday_id\": 0.0,\n",
    "  \"holiday\": 0.0,\n",
    "  \"school\": 0.0,\n",
    "  \"dt_year\": 2019.0,\n",
    "  \"dt_month\": 1.0,\n",
    "  \"dt_day\": 8.0,\n",
    "  \"dt_hour\": 20.0\n",
    "}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(df_full.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "cols = ['nat_demand',\n",
    "        't2m_toc',\n",
    "        'qv2m_toc',\n",
    "        'tql_toc',\n",
    "        'w2m_toc',\n",
    "        't2m_san',\n",
    "        'qv2m_san',\n",
    "        'tql_san',\n",
    "        'w2m_san',\n",
    "        't2m_dav',\n",
    "        'qv2m_dav',\n",
    "        'tql_dav',\n",
    "        'w2m_dav',\n",
    "        'holiday_id',\n",
    "        'holiday',\n",
    "        'school',\n",
    "        'dt',\n",
    "        'dt_year',\n",
    "        'dt_month',\n",
    "        'dt_day',\n",
    "        'dt_hour']\n",
    "json_full = df_full[cols][:500].to_json(orient='records')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "import json\n",
    "parsed_json = json.loads(json_full)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "with open(\"assets/output.json\", 'w') as f_out:\n",
    "  json.dump(parsed_json, f_out)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "json_full"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
